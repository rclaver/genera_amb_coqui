usage: tts [-h] [--list_models [LIST_MODELS]]
           [--model_info_by_idx MODEL_INFO_BY_IDX]
           [--model_info_by_name MODEL_INFO_BY_NAME]
           [--text TEXT]
           [--model_name MODEL_NAME]
           [--vocoder_name VOCODER_NAME]
           [--config_path CONFIG_PATH]
           [--model_path MODEL_PATH]
           [--out_path OUT_PATH]
           [--use_cuda USE_CUDA]
           [--device DEVICE]
           [--vocoder_path VOCODER_PATH]
           [--vocoder_config_path VOCODER_CONFIG_PATH]
           [--encoder_path ENCODER_PATH]
           [--encoder_config_path ENCODER_CONFIG_PATH]
           [--pipe_out [PIPE_OUT]]
           [--speakers_file_path SPEAKERS_FILE_PATH]
           [--language_ids_file_path LANGUAGE_IDS_FILE_PATH]
           [--speaker_idx SPEAKER_IDX]
           [--language_idx LANGUAGE_IDX]
           [--speaker_wav SPEAKER_WAV [SPEAKER_WAV ...]]
           [--gst_style GST_STYLE]
           [--capacitron_style_wav CAPACITRON_STYLE_WAV]
           [--capacitron_style_text CAPACITRON_STYLE_TEXT]
           [--list_speaker_idxs [LIST_SPEAKER_IDXS]]
           [--list_language_idxs [LIST_LANGUAGE_IDXS]]
           [--save_spectogram SAVE_SPECTOGRAM]
           [--reference_wav REFERENCE_WAV]
           [--reference_speaker_idx REFERENCE_SPEAKER_IDX]
           [--progress_bar PROGRESS_BAR]
           [--source_wav SOURCE_WAV]
           [--target_wav TARGET_WAV]
           [--voice_dir VOICE_DIR]

Synthesize speech on command line.

You can either use your trained model or choose a model from the provided list.

If you don't specify any models, then it uses LJSpeech based English model.

#### Single Speaker Models

- List provided models:

  ```
  $ tts --list_models
  ```

- Get model info (for both tts_models and vocoder_models):

  - Query by type/name:
    The model_info_by_name uses the name as it from the --list_models.
    $ tts --model_info_by_name "<model_type>/<language>/<dataset>/<model_name>"
    For example:
    $ tts --model_info_by_name tts_models/tr/common-voice/glow-tts
    $ tts --model_info_by_name vocoder_models/en/ljspeech/hifigan_v2
  - Query by type/idx:
    The model_query_idx uses the corresponding idx from --list_models.

    $ tts --model_info_by_idx "<model_type>/<model_query_idx>"

    For example:

    $ tts --model_info_by_idx tts_models/3

  - Query info for model info by full name:
    $ tts --model_info_by_name "<model_type>/<language>/<dataset>/<model_name>"

- Run TTS with default models:

  ```
  $ tts --text "Text for TTS" --out_path output/path/speech.wav
  ```

- Run TTS and pipe out the generated TTS wav file data:

  ```
  $ tts --text "Text for TTS" --pipe_out --out_path output/path/speech.wav | aplay
  ```

- Run a TTS model with its default vocoder model:

  ```
  $ tts --text "Text for TTS" --model_name "<model_type>/<language>/<dataset>/<model_name>" --out_path output/path/speech.wav
  ```

  For example:

  ```
  $ tts --text "Text for TTS" --model_name "tts_models/en/ljspeech/glow-tts" --out_path output/path/speech.wav
  ```

- Run with specific TTS and vocoder models from the list:

  ```
  $ tts --text "Text for TTS" --model_name "<model_type>/<language>/<dataset>/<model_name>" --vocoder_name "<model_type>/<language>/<dataset>/<model_name>" --out_path output/path/speech.wav
  ```

  For example:

  ```
  $ tts --text "Text for TTS" --model_name "tts_models/en/ljspeech/glow-tts" --vocoder_name "vocoder_models/en/ljspeech/univnet" --out_path output/path/speech.wav
  ```

- Run your own TTS model (Using Griffin-Lim Vocoder):

  ```
  $ tts --text "Text for TTS" --model_path path/to/model.pth --config_path path/to/config.json --out_path output/path/speech.wav
  ```

- Run your own TTS and Vocoder models:

  ```
  $ tts --text "Text for TTS" --model_path path/to/model.pth --config_path path/to/config.json --out_path output/path/speech.wav
      --vocoder_path path/to/vocoder.pth --vocoder_config_path path/to/vocoder_config.json
  ```

#### Multi-speaker Models

- List the available speakers and choose a <speaker_id> among them:

  ```
  $ tts --model_name "<language>/<dataset>/<model_name>"  --list_speaker_idxs
  ```

- Run the multi-speaker TTS model with the target speaker ID:

  ```
  $ tts --text "Text for TTS." --out_path output/path/speech.wav --model_name "<language>/<dataset>/<model_name>"  --speaker_idx <speaker_id>
  ```
  speaker_idxs {'jan': 250, 'mar': 251, 'ona': 252, 'pau': 253, 'pep': 254, 'pol': 255, 'teo': 256}


- Run your own multi-speaker TTS model:

  ```
  $ tts --text "Text for TTS" --out_path output/path/speech.wav --model_path path/to/model.pth --config_path path/to/config.json --speakers_file_path path/to/speaker.json --speaker_idx <speaker_id>
  ```

### Voice Conversion Models

```
$ tts --out_path output/path/speech.wav --model_name "<language>/<dataset>/<model_name>" --source_wav <path/to/speaker/wav> --target_wav <path/to/reference/wav>
```

options:
  -h, --help                              show this help message and exit
  --list_models [LIST_MODELS]             list available pre-trained TTS and vocoder models.
  --model_info_by_idx MODEL_INFO_BY_IDX   model info using query format: <model_type>/<model_query_idx>
  --model_info_by_name MODEL_INFO_BY_NAME model info using query format: <model_type>/<language>/<dataset>/<model_name>
  --text TEXT                             Text to generate speech.
  --model_name MODEL_NAME                 Name of one of the pre-trained TTS models in format <language>/<dataset>/<model_name>
  --vocoder_name VOCODER_NAME             Name of one of the pre-trained  vocoder models in format <language>/<dataset>/<model_name>
  --config_path CONFIG_PATH               Path to model config file.
  --model_path MODEL_PATH                 Path to model file.
  --out_path OUT_PATH                     Output wav file path.
  --use_cuda USE_CUDA                     Run model on CUDA.
  --device DEVICE                         Device to run model on.
  --vocoder_path VOCODER_PATH             Path to vocoder model file. If it is not defined, model uses GL as vocoder.
                                          Please make sure that you installed vocoder library before (WaveRNN).
  --vocoder_config_path VOCODER_CONFIG_PATH  Path to vocoder model config file.
  --encoder_path ENCODER_PATH                Path to speaker encoder model file.
  --encoder_config_path ENCODER_CONFIG_PATH  Path to speaker encoder config file.
  --pipe_out [PIPE_OUT]                      stdout the generated TTS wav file for shell pipe.
  --speakers_file_path SPEAKERS_FILE_PATH          JSON file for multi-speaker model.
  --language_ids_file_path LANGUAGE_IDS_FILE_PATH  JSON file for multi-lingual model.
  --speaker_idx SPEAKER_IDX                        Target speaker ID for a multi-speaker TTS model.
  --language_idx LANGUAGE_IDX                      Target language ID for a multi-lingual TTS model.
  --speaker_wav SPEAKER_WAV [SPEAKER_WAV ...]      wav file(s) to condition a multi-speaker TTS model with a Speaker Encoder.
                                                   You can give multiple file paths. The d_vectors is computed as their average.
  --gst_style GST_STYLE                            Wav path file for GST style reference.
  --capacitron_style_wav CAPACITRON_STYLE_WAV      Wav path file for Capacitron prosody reference.
  --capacitron_style_text CAPACITRON_STYLE_TEXT    Transcription of the reference.
  --list_speaker_idxs [LIST_SPEAKER_IDXS]          List available speaker ids for the defined multi-speaker model.
  --list_language_idxs [LIST_LANGUAGE_IDXS]        List available language ids for the defined multi-lingual model.
  --save_spectogram SAVE_SPECTOGRAM                If true save raw spectogram for further (vocoder) processing in out_path.
  --reference_wav REFERENCE_WAV                    Reference wav file to convert in the voice of the speaker_idx or speaker_wav
  --reference_speaker_idx REFERENCE_SPEAKER_IDX    speaker ID of the reference_wav speaker (If not provided the embedding will be computed using the Speaker Encoder).
  --progress_bar PROGRESS_BAR                      If true shows a progress bar for the model download. Defaults to True
  --source_wav SOURCE_WAV                          Original audio file to convert in the voice of the target_wav
  --target_wav TARGET_WAV                          Target audio file to convert in the voice of the source_wav
  --voice_dir VOICE_DIR                            Voice dir for tortoise model
